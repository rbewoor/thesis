
			Find validation losses on already trained decoder model - all with BS=64
	Script: ImgCap_Check_Val_Loss_Lappy_1.py
## compile model - note that all layers frozen as model set as trainable = False during loading
reloaded_RNN_decoder.compile(loss='categorical_crossentropy', metrics=['accuracy'])

## make data suitable to use for model evaluation step
inputs, outputs = create_data_for_evaluation(descriptions_arr, imgs_encodings_arr, wordtoix, MAX_LENGTH_CAPTION, VOCAB_SIZE)

start_timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
start_tick = time.time()

print(f"\n\nStarted at = {start_timestamp}\n")

## evaluate it and get score
model_loss = reloaded_RNN_decoder.evaluate(inputs, outputs, batch_size=BATCH_SIZE)
print(f"\n\nLoss with Batch size of {BATCH_SIZE} =\n{model_loss}\n\n")

---------------------------------------------------------
			Validation Dataset (3k images) Losses AFTER model is trained - so technically used it as a Test set loss
			Run on Model 3 - Epoch 2 to 18
			MODEL 3			MODEL 3			MODEL 3			MODEL 3			MODEL 3
---------------------------------------------------------

python3 ImgCap_Check_Val_Loss_Lappy_1.py -wtfile "/media/rohit/DATA/EverythingD/01SRH-BDBA Acads/Thesis/StoryGenerator/Code/ModelsRuns/ImgCap/SavedData/Thesis_ImgCap_Weights_In_Run3/Decoder_Run_3_Wt_ep_18.h5"

(ce7comb1) rohit@rohitu2004lts:~/PyWDUbuntu/thesis$ python3 ImgCap_Check_Val_Loss_Lappy_1.py -wtfile "/media/rohit/DATA/EverythingD/01SRH-BDBA Acads/Thesis/StoryGenerator/Code/ModelsRuns/ImgCap/SavedData/Thesis_ImgCap_Weights_In_Run3/Decoder_Run_3_Wt_ep_18.h5"

Check wordtoix entries ::
startseq = 1	endseq = 9	bird = 974
Check ixtoword entries ::
ix 1 = startseq	ix 10 = red	ix 974 = bird

2020-10-09 01:45:21.473022: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-10-09 01:45:21.503822: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz
2020-10-09 01:45:21.504628: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f5af12d200 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-09 01:45:21.504660: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-09 01:45:21.504813: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.

SUCCESS - Reloaded weights from :: /media/rohit/DATA/EverythingD/01SRH-BDBA Acads/Thesis/StoryGenerator/Code/ModelsRuns/ImgCap/SavedData/Thesis_ImgCap_Weights_In_Run3/Decoder_Run_3_Wt_ep_18.h5

RNN Decoder model (non-trainable type) defined with these paramenters:
EMBEDDING_DIMS = 200 , VOCAB_SIZE = 6758 , MAX_LENGTH_CAPTION = 49
Attempting to load weights...

Length of Descriptions dict = 3000



Started at = 2020-10-09 01:45:35

116287/116287 [==============================] - 536s 5ms/sample - loss: 3.0886 - accuracy: 0.3635


Loss with Batch size of 64 =
[3.088649831643242, 0.3634628]




Ended at = 2020-10-09 01:54:35
Time taken = 539.990523815155 seconds


Done

(ce7comb1) rohit@rohitu2004lts:~/PyWDUbuntu/thesis$

---------------------------------------------------------

		Epoch 18
116287/116287 [==============================] - 536s 5ms/sample - loss: 3.0886 - accuracy: 0.3635
Loss with Batch size of 64 =
[3.088649831643242, 0.3634628]
		Epoch 16
116287/116287 [==============================] - 516s 4ms/sample - loss: 3.0937 - accuracy: 0.3632
Loss with Batch size of 64 =
[3.0936912543075312, 0.36319622]
		Epoch 14
116287/116287 [==============================] - 516s 4ms/sample - loss: 3.0882 - accuracy: 0.3629
Loss with Batch size of 64 =
[3.088215761960429, 0.36293826]
		AGAIN Epoch 14
116287/116287 [==============================] - 520s 4ms/sample - loss: 3.0882 - accuracy: 0.3629
Loss with Batch size of 64 =
[3.088215761960429, 0.36293826]
		Epoch 12
116287/116287 [==============================] - 522s 4ms/sample - loss: 3.1133 - accuracy: 0.3587
Loss with Batch size of 64 =
[3.113307865008768, 0.35872453]
		Epoch 10
116287/116287 [==============================] - 519s 4ms/sample - loss: 3.1144 - accuracy: 0.3584
Loss with Batch size of 64 =
[3.11437327314346, 0.35841495]
		Epoch 8
116287/116287 [==============================] - 516s 4ms/sample - loss: 3.1233 - accuracy: 0.3563
Loss with Batch size of 64 =
[3.1233026144950213, 0.3562565]
		Epoch 6
116287/116287 [==============================] - 526s 5ms/sample - loss: 3.1429 - accuracy: 0.3537
Loss with Batch size of 64 =
[3.142919300563814, 0.35367668]
		Epoch 4
116287/116287 [==============================] - 516s 4ms/sample - loss: 3.1752 - accuracy: 0.3472
Loss with Batch size of 64 =
[3.1751763146481715, 0.3471755]
		Epoch 2
116287/116287 [==============================] - 517s 4ms/sample - loss: 3.2749 - accuracy: 0.3328
Loss with Batch size of 64 =
[3.2749193742732507, 0.3327801]


---------------------------------------------------------
			Validation Dataset (3k images) Losses AFTER model is trained - so technically used it as a Test set loss
			Run on Model 2 - Epoch 2 to 10
			MODEL 2			MODEL 2			MODEL 2			MODEL 2			MODEL 2
---------------------------------------------------------

python3 ImgCap_Check_Val_Loss_Lappy_1.py -wtfile "/media/rohit/DATA/EverythingD/01SRH-BDBA Acads/Thesis/StoryGenerator/Code/ModelsRuns/ImgCap/SavedData/Thesis_ImgCap_Weights_In_Run2/Decoder_Run_2_Wt_ep_10.h5"

(ce7comb1) rohit@rohitu2004lts:~/PyWDUbuntu/thesis$ python3 ImgCap_Check_Val_Loss_Lappy_1.py -wtfile "/media/rohit/DATA/EverythingD/01SRH-BDBA Acads/Thesis/StoryGenerator/Code/ModelsRuns/ImgCap/SavedData/Thesis_ImgCap_Weights_In_Run2/Decoder_Run_2_Wt_ep_10.h5"

Check wordtoix entries ::
startseq = 1	endseq = 9	bird = 974
Check ixtoword entries ::
ix 1 = startseq	ix 10 = red	ix 974 = bird

2020-10-09 13:53:48.592726: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-10-09 13:53:48.623552: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz
2020-10-09 13:53:48.624314: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55da6b9233b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-09 13:53:48.624350: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-09 13:53:48.624474: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.

SUCCESS - Reloaded weights from :: /media/rohit/DATA/EverythingD/01SRH-BDBA Acads/Thesis/StoryGenerator/Code/ModelsRuns/ImgCap/SavedData/Thesis_ImgCap_Weights_In_Run2/Decoder_Run_2_Wt_ep_10.h5

RNN Decoder model (non-trainable type) defined with these paramenters:
EMBEDDING_DIMS = 200 , VOCAB_SIZE = 6758 , MAX_LENGTH_CAPTION = 49
Attempting to load weights...

Length of Descriptions dict = 3000



Started at = 2020-10-09 13:54:01

116287/116287 [==============================] - 528s 5ms/sample - loss: 3.2169 - accuracy: 0.3365


Loss with Batch size of 64 =
[3.2169498203267946, 0.33647785]




Ended at = 2020-10-09 14:02:53
Time taken = 531.6395823955536 seconds


Done

(ce7comb1) rohit@rohitu2004lts:~/PyWDUbuntu/thesis$

---------------------------------------------------------

		Epoch 10
116287/116287 [==============================] - 528s 5ms/sample - loss: 3.2169 - accuracy: 0.3365
Loss with Batch size of 64 =
[3.2169498203267946, 0.33647785]
		Epoch 8
116287/116287 [==============================] - 476s 4ms/sample - loss: 3.2466 - accuracy: 0.3332
Loss with Batch size of 64 =
[3.2466391558613816, 0.3331585]
		Epoch 6
116287/116287 [==============================] - 436s 4ms/sample - loss: 3.2908 - accuracy: 0.3282
Loss with Batch size of 64 =
[3.290836356369273, 0.328231]
		Epoch 4
116287/116287 [==============================] - 489s 4ms/sample - loss: 3.3666 - accuracy: 0.3184
Loss with Batch size of 64 =
[3.3666324971813695, 0.31841907]
		Epoch 2
116287/116287 [==============================] - 351s 3ms/sample - loss: 3.5284 - accuracy: 0.2984
Loss with Batch size of 64 =
[3.5284207623579418, 0.29835665]


