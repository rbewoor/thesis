		Decoder parameters:
EMBEDDING_DIMS = 200
VOCAB_SIZE = 6761
MAX_LENGTH_CAPTION = 49


		Training parameters:
LR_1 = 0.0002
BATCH_SIZE_1 = 128   ## how many images per batch
N_EPOCHS_1 = 5
Adam optimizer


		Console output during training:
MODEL 2 :: Training Phase 1 started at :: 12:34:31


Phase 1 parameters:
STEPS_PER_EPOCH_1 = 757
BATCH_SIZE_1 = 128
N_EPOCHS_1 = 5

Epoch 1 started at 12:34:31
LR used = 0.00019999999494757503 

757/757 [==============================] - 5051s 7s/step - loss: 4.9100

Epoch 2 started at 13:58:54
LR used = 0.00019999999494757503 

757/757 [==============================] - 5074s 7s/step - loss: 3.8901

Epoch 3 started at 15:23:35
LR used = 0.00019999999494757503 

757/757 [==============================] - 5080s 7s/step - loss: 3.6190

Epoch 4 started at 16:48:23
LR used = 0.00019999999494757503 

757/757 [==============================] - 5097s 7s/step - loss: 3.4708

Epoch 5 started at 18:13:26
LR used = 0.00019999999494757503 

757/757 [==============================] - 5129s 7s/step - loss: 3.3735






