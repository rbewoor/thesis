----------------------- ************************************ -----------------------
----------------------- ************************************ -----------------------
----------------------- ************************************ -----------------------
----------------------- ************************************ -----------------------

				ABOUT MODEL SETUP

unique words in original vocabulary = 24323
unique words in culled vocab vocab_threshold = 6757
thus, VOCAB_SIZE = 6757 + 1 = 6758

	Encodings data:
len(img_encodings_train) = 97000
len(img_encodings_val) = 3000
	Descriptions data:
len(descriptions_train) = 97000
len(descriptions_val) = 3000

No Validation Set being used for now.

len(wordtoix) = 6757
VOCAB_SIZE = 6758
EMBEDDING_DIMS = 200
embedding_matrix Shape = (6758, 200)
MAX_LENGTH_CAPTION = 49

		Parameter Count Before freezing embeddings layer:
#Total params: 4,146,710
#Trainable params: 4,146,710
#Non-trainable params: 0

		Parameter Count After freezing embeddings layer:
#Total params: 4,146,710
#Trainable params: 2,795,110
#Non-trainable params: 1,351,600



		Decoder parameters:
EMBEDDING_DIMS = 200
VOCAB_SIZE = 6758
MAX_LENGTH_CAPTION = 49

----------------------- ************************************ -----------------------
----------------------- ************************************ -----------------------
----------------------- ************************************ -----------------------
----------------------- ************************************ -----------------------

				TRAINING PHASE 1 to 4 i.e. run2_1, run2_2, run2_3, run2_4 - total 10 epochs

Epoch 1 started at 17:15:11
LR used = 0.0005000000237487257 

757/757 [==============================] - 7705s 10s/step - loss: 4.3657

Epoch 2 started at 19:23:55
LR used = 0.0005000000237487257 

757/757 [==============================] - 7793s 10s/step - loss: 3.4819

Epoch 3 started at 23:57:01
LR used = 0.00019999999494757503

757/757 [==============================] - 7822s 10s/step - loss: 3.2969

Epoch 4 started at 02:07:43
LR used = 0.00019999999494757503

757/757 [==============================] - 7808s 10s/step - loss: 3.2286

Epoch 5 started at 08:28:14
LR used = 0.00019999999494757503

757/757 [==============================] - 7752s 10s/step - loss: 3.1868

Epoch 6 started at 10:37:46
LR used = 0.00019999999494757503

757/757 [==============================] - 7795s 10s/step - loss: 3.1432

Epoch 7 started at 12:47:52
LR used = 0.00019999999494757503

722/757 [===========================>..] - ETA: 5:59 - loss: 3.1114

Epoch 8 started at 16:56:07
LR used = 9.999999747378752e-05

1515/1515 [==============================] - 7329s 5s/step - loss: 3.0858

Epoch 9 started at 18:58:27
LR used = 9.999999747378752e-05

1515/1515 [==============================] - 7264s 5s/step - loss: 3.0619

Epoch 10 started at 20:59:36
LR used = 9.999999747378752e-05

1515/1515 [==============================] - 7340s 5s/step - loss: 3.0448





----------------------- ************************************ -----------------------
----------------------- ************************************ -----------------------
----------------------- ************************************ -----------------------
----------------------- ************************************ -----------------------

				TRAINING PHASE 1

		Training parameters - Phase 1:
LR_1 = 0.0005
BATCH_SIZE_1 = 128   ## how many images per batch
N_EPOCHS_1 = 2
Adam optimizer


Epoch 1 started at 17:15:11
LR used = 0.0005000000237487257 

757/757 [==============================] - 7705s 10s/step - loss: 4.3657

Epoch 2 started at 19:23:55
LR used = 0.0005000000237487257 

757/757 [==============================] - 7793s 10s/step - loss: 3.4819


----------------------- ************************************ -----------------------
----------------------- ************************************ -----------------------
----------------------- ************************************ -----------------------
----------------------- ************************************ -----------------------

				TRAINING PHASE 2

		Training parameters - PHASE 2:
LR_2 = 0.0002
BATCH_SIZE_2 = 128   ## how many images per batch
N_EPOCHS_2 = 2
Adam optimizer


Epoch 3 started at 23:57:01
LR used = 0.00019999999494757503

757/757 [==============================] - 7822s 10s/step - loss: 3.2969

Epoch 4 started at 02:07:43
LR used = 0.00019999999494757503

757/757 [==============================] - 7808s 10s/step - loss: 3.2286

----------------------- ************************************ -----------------------
----------------------- ************************************ -----------------------
----------------------- ************************************ -----------------------
----------------------- ************************************ -----------------------

				TRAINING PHASE 3

		Training parameters - PHASE 3:
LR_3 = 0.0002
BATCH_SIZE_3 = 128   ## how many images per batch
N_EPOCHS_3 = 3
Adam optimizer


Epoch 5 started at 08:28:14
LR used = 0.00019999999494757503

757/757 [==============================] - 7752s 10s/step - loss: 3.1868

Epoch 6 started at 10:37:46
LR used = 0.00019999999494757503

757/757 [==============================] - 7795s 10s/step - loss: 3.1432

Epoch 7 started at 12:47:52
LR used = 0.00019999999494757503

722/757 [===========================>..] - ETA: 5:59 - loss: 3.1114

----------------------- ************************************ -----------------------
----------------------- ************************************ -----------------------
----------------------- ************************************ -----------------------
----------------------- ************************************ -----------------------

				TRAINING PHASE 4

		Training parameters - PHASE 4:
LR_4 = 0.0001
BATCH_SIZE_4 = 64   ## how many images per batch
N_EPOCHS_4 = 3
Adam optimizer



Epoch 8 started at 16:56:07
LR used = 9.999999747378752e-05

1515/1515 [==============================] - 7329s 5s/step - loss: 3.0858

Epoch 9 started at 18:58:27
LR used = 9.999999747378752e-05

1515/1515 [==============================] - 7264s 5s/step - loss: 3.0619

Epoch 10 started at 20:59:36
LR used = 9.999999747378752e-05

1515/1515 [==============================] - 7340s 5s/step - loss: 3.0448



